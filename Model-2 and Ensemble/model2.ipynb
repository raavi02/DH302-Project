{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1267593,"sourceType":"datasetVersion","datasetId":723383},{"sourceId":1299795,"sourceType":"datasetVersion","datasetId":751906},{"sourceId":1653290,"sourceType":"datasetVersion","datasetId":978569},{"sourceId":5873416,"sourceType":"datasetVersion","datasetId":3345892},{"sourceId":6760675,"sourceType":"datasetVersion","datasetId":3891249},{"sourceId":6760741,"sourceType":"datasetVersion","datasetId":3891280},{"sourceId":6760750,"sourceType":"datasetVersion","datasetId":3891286},{"sourceId":6761298,"sourceType":"datasetVersion","datasetId":3891520}],"dockerImageVersionId":30498,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing libraries","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nimport os\nimport time\nfrom random import randint\n \nimport gc \nimport numpy as np\nfrom scipy import stats\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import KFold\n\nimport nibabel as nib\nimport pydicom as pdm\nimport nilearn as nl\nimport nilearn.plotting as nlplt\nimport h5py\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nimport matplotlib.animation as anim\nimport matplotlib.patches as mpatches\nimport matplotlib.gridspec as gridspec\n\nimport seaborn as sns\nimport imageio\nfrom skimage.transform import resize\nfrom skimage.util import montage\n\nfrom IPython.display import Image as show_gif\nfrom IPython.display import clear_output\nfrom IPython.display import YouTubeVideo\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\n\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.nn import MSELoss\n\n# !pip install albumentations==0.4.6\nimport albumentations as A\n# from albumentations.pytorch import ToTensor, ToTensorV2\n\n\nfrom albumentations import Compose, HorizontalFlip\n# from albumentations.pytorch import ToTensor, ToTensorV2 \n\nimport warnings\nwarnings.simplefilter(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-10-22T03:56:55.270557Z","iopub.execute_input":"2023-10-22T03:56:55.271386Z","iopub.status.idle":"2023-10-22T03:57:00.843934Z","shell.execute_reply.started":"2023-10-22T03:56:55.271347Z","shell.execute_reply":"2023-10-22T03:57:00.842848Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Data loading","metadata":{}},{"cell_type":"code","source":"class GlobalConfig:\n    root_dir = '../input/brats20-dataset-training-validation'\n    train_root_dir = '../input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData'\n    test_root_dir = '../input/brats20-dataset-training-validation/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData'\n    path_to_csv = './train_data.csv'\n    pretrained_model_path = '../input/brats20logs/brats2020logs/unet/last_epoch_model.pth'\n    train_logs_path = '../input/brats20logs/brats2020logs/unet/train_log.csv'\n    ae_pretrained_model_path = '../input/brats20logs/brats2020logs/ae/autoencoder_best_model.pth'\n    tab_data = '../input/brats20logs/brats2020logs/data/df_with_voxel_stats_and_latent_features.csv'\n    seed = 55\n    \ndef seed_everything(seed: int):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n    \nconfig = GlobalConfig()\nseed_everything(config.seed)","metadata":{"execution":{"iopub.status.busy":"2023-10-22T03:57:03.647976Z","iopub.execute_input":"2023-10-22T03:57:03.648341Z","iopub.status.idle":"2023-10-22T03:57:03.691453Z","shell.execute_reply.started":"2023-10-22T03:57:03.648310Z","shell.execute_reply":"2023-10-22T03:57:03.690691Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Data preprocessing","metadata":{}},{"cell_type":"code","source":"# data pre-processing time starts(dpp0)\ndpp0 = time.time() ","metadata":{"execution":{"iopub.status.busy":"2023-10-22T03:57:03.693576Z","iopub.execute_input":"2023-10-22T03:57:03.693887Z","iopub.status.idle":"2023-10-22T03:57:03.698265Z","shell.execute_reply.started":"2023-10-22T03:57:03.693852Z","shell.execute_reply":"2023-10-22T03:57:03.697359Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"survival_info_df = pd.read_csv('../input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/survival_info.csv')\nname_mapping_df = pd.read_csv('../input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/name_mapping.csv')\n\nname_mapping_df.rename({'BraTS_2020_subject_ID': 'Brats20ID'}, axis=1, inplace=True) \n\n\ndf = survival_info_df.merge(name_mapping_df, on=\"Brats20ID\", how=\"right\")\n\n# renaming & merging into one dataframe","metadata":{"execution":{"iopub.status.busy":"2023-10-22T03:57:03.699446Z","iopub.execute_input":"2023-10-22T03:57:03.699711Z","iopub.status.idle":"2023-10-22T03:57:03.742632Z","shell.execute_reply.started":"2023-10-22T03:57:03.699688Z","shell.execute_reply":"2023-10-22T03:57:03.741838Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"paths = []\nfor _, row  in df.iterrows():\n    \n    id_ = row['Brats20ID']\n    phase = id_.split(\"_\")[-2]\n    if phase == 'Training':\n        path = os.path.join(config.train_root_dir, id_)\n    else:\n        path = os.path.join(config.test_root_dir, id_)\n    paths.append(path)\n    \ndf['path'] = paths\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-22T03:57:03.743627Z","iopub.execute_input":"2023-10-22T03:57:03.743875Z","iopub.status.idle":"2023-10-22T03:57:03.772177Z","shell.execute_reply.started":"2023-10-22T03:57:03.743854Z","shell.execute_reply":"2023-10-22T03:57:03.771197Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Data cleaning - removing all null age entries\ntrain_data = df.loc[df['Age'].notnull()].reset_index(drop=True)\n\n# Calculating Age rank for the basis of K - Fold stratification\ntrain_data[\"Age_rank\"] =  train_data[\"Age\"] // 10 * 10\ntrain_data = train_data.loc[train_data['Brats20ID'] != 'BraTS20_Training_355'].reset_index(drop=True, )\n\nlen(df)","metadata":{"execution":{"iopub.status.busy":"2023-10-22T03:57:04.144678Z","iopub.execute_input":"2023-10-22T03:57:04.145324Z","iopub.status.idle":"2023-10-22T03:57:04.156181Z","shell.execute_reply.started":"2023-10-22T03:57:04.145295Z","shell.execute_reply":"2023-10-22T03:57:04.155241Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"369"},"metadata":{}}]},{"cell_type":"code","source":"# stratified k-fold ( skf ) time starts \nskf0 = time.time() ","metadata":{"execution":{"iopub.status.busy":"2023-10-22T03:57:04.450630Z","iopub.execute_input":"2023-10-22T03:57:04.451352Z","iopub.status.idle":"2023-10-22T03:57:04.455208Z","shell.execute_reply.started":"2023-10-22T03:57:04.451323Z","shell.execute_reply":"2023-10-22T03:57:04.454335Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"skf = StratifiedKFold(\n    n_splits=7, random_state=config.seed, shuffle=True\n)\n\n# enumeratng all entries for defining the fold number \n# assigning the fold number in increment order \nfor i, (train_index, val_index) in enumerate(\n        skf.split(train_data, train_data[\"Age_rank\"])\n        ):\n        train_data.loc[val_index, \"fold\"] = i","metadata":{"execution":{"iopub.status.busy":"2023-10-22T03:57:04.730653Z","iopub.execute_input":"2023-10-22T03:57:04.731024Z","iopub.status.idle":"2023-10-22T03:57:04.745664Z","shell.execute_reply.started":"2023-10-22T03:57:04.730996Z","shell.execute_reply":"2023-10-22T03:57:04.744632Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# total stratification time(skft) \nskf1 = time.time()\nskft = skf1 - skf0 \nprint(\"Stratification time : \",skft ) ","metadata":{"execution":{"iopub.status.busy":"2023-10-22T03:57:05.066770Z","iopub.execute_input":"2023-10-22T03:57:05.067139Z","iopub.status.idle":"2023-10-22T03:57:05.072673Z","shell.execute_reply.started":"2023-10-22T03:57:05.067109Z","shell.execute_reply":"2023-10-22T03:57:05.071580Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Stratification time :  0.616034746170044\n","output_type":"stream"}]},{"cell_type":"code","source":"# splitting of the data wasn't done for train , test &  validation data \ntrain_df = train_data.loc[train_data['fold'] != 0].reset_index(drop=True)\nval_df = train_data.loc[train_data['fold'] == 0].reset_index(drop=True)\n\n# selecting the rows where the AGE col. is null --> test_df \ntest_df = df.loc[~df['Age'].notnull()].reset_index(drop=True)\nprint(\"train_df ->\", train_df.shape, \"val_df ->\", val_df.shape, \"test_df ->\", test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2023-10-22T03:57:05.548365Z","iopub.execute_input":"2023-10-22T03:57:05.549270Z","iopub.status.idle":"2023-10-22T03:57:05.558670Z","shell.execute_reply.started":"2023-10-22T03:57:05.549235Z","shell.execute_reply":"2023-10-22T03:57:05.557669Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"train_df -> (201, 12) val_df -> (34, 12) test_df -> (133, 10)\n","output_type":"stream"}]},{"cell_type":"code","source":"# total data pre-processing time(dppt)\ndpp1 = time.time() \ndppt = dpp1 - dpp0 - skft\nprint(\"Data preprocessing time : \", dppt  ) ","metadata":{"execution":{"iopub.status.busy":"2023-10-22T03:57:06.294503Z","iopub.execute_input":"2023-10-22T03:57:06.295194Z","iopub.status.idle":"2023-10-22T03:57:06.300332Z","shell.execute_reply.started":"2023-10-22T03:57:06.295162Z","shell.execute_reply":"2023-10-22T03:57:06.299344Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Data preprocessing time :  1.9855406284332275\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data.to_csv(\"train_data.csv\", index=False)\ntest_df.to_csv(\"test_df.csv\", index=False)\ntrain_df.to_csv(\"train_df.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-22T03:57:10.650608Z","iopub.execute_input":"2023-10-22T03:57:10.651340Z","iopub.status.idle":"2023-10-22T03:57:10.669104Z","shell.execute_reply.started":"2023-10-22T03:57:10.651304Z","shell.execute_reply":"2023-10-22T03:57:10.668279Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Dataset dataLoader","metadata":{}},{"cell_type":"code","source":"class BratsDataset(Dataset):\n    def __init__(self, df: pd.DataFrame, phase: str=\"test\", is_resize: bool=False):\n        self.df = df\n        self.phase = phase\n        self.augmentations = get_augmentations(phase)\n        self.data_types = ['_flair.nii', '_t1.nii', '_t1ce.nii', '_t2.nii']\n        self.is_resize = is_resize\n        \n    def __len__(self):\n        return self.df.shape[0] \n    \n    def __getitem__(self, idx):\n        # at a specified index ( idx ) select the value under 'Brats20ID' & asssign it to id_ \n        id_ = self.df.loc[idx, 'Brats20ID']\n        \n        # As we've got the id_ , now find the path of the entry by asserting the Brats20ID to id_ \n        root_path = self.df.loc[self.df['Brats20ID'] == id_]['path'].values[0]\n        \n        # load all modalities\n        images = []\n        \n        for data_type in self.data_types:\n            # here data_type is appended to the root path, as it only contains the name without the datatype such as .nii etc\n            img_path = os.path.join(root_path, id_ + data_type) \n            img = self.load_img(img_path)#.transpose(2, 0, 1)\n            \n            if self.is_resize:\n                img = self.resize(img)\n    \n            img = self.normalize(img)\n            images.append(img)\n            \n        # stacking all the t1 , t1ce , t2 , t2 flair files of a single ID in a stack \n        img = np.stack(images)\n        img = np.moveaxis(img, (0, 1, 2, 3), (0, 3, 2, 1))\n        \n        if self.phase != \"test\":\n            mask_path =  os.path.join(root_path, id_ + \"_seg.nii\")\n            mask = self.load_img(mask_path)\n            \n            if self.is_resize:\n                mask = self.resize(mask)\n                # mask --> conversion to uint8 --> normalization / clipping ( 0 to 1 ) --> conversion to float32 \n                mask = np.clip(mask.astype(np.uint8), 0, 1).astype(np.float32)\n                # again clipping ( 0 to 1 ) \n                mask = np.clip(mask, 0, 1)\n            \n            # setting the mask labels 1 , 2 , 4 for the mask file ( _seg.ii ) \n            mask = self.preprocess_mask_labels(mask)\n    \n            augmented = self.augmentations(image=img.astype(np.float32), \n                                           mask=mask.astype(np.float32))\n            # Several augmentations / transformations like flipping, rotating, padding will be applied to both the images \n            img = augmented['image']\n            mask = augmented['mask']\n    \n        \n            return {\n                \"Id\": id_,\n                \"image\": img,\n                \"mask\": mask,\n            }\n        \n        return {\n            \"Id\": id_,\n            \"image\": img,\n        }\n    \n    def load_img(self, file_path):\n        data = nib.load(file_path)\n        data = np.asarray(data.dataobj)\n        return data\n    \n    def normalize(self, data: np.ndarray):\n        data_min = np.min(data)\n        # normalization = (each element - min element) / ( max - min ) \n        return (data - data_min) / (np.max(data) - data_min)\n    \n    def resize(self, data: np.ndarray):\n        data = resize(data, (78, 120, 120), preserve_range=True)\n        return data\n    \n    def preprocess_mask_labels(self, mask: np.ndarray):\n\n        # whole tumour\n        mask_WT = mask.copy()\n        mask_WT[mask_WT == 1] = 1\n        mask_WT[mask_WT == 2] = 1\n        mask_WT[mask_WT == 4] = 1\n        # include all tumours \n\n        # NCR / NET - LABEL 1\n        mask_TC = mask.copy()\n        mask_TC[mask_TC == 1] = 1\n        mask_TC[mask_TC == 2] = 0\n        mask_TC[mask_TC == 4] = 1\n        # exclude 2 / 4 labelled tumour \n        \n        # ET - LABEL 4 \n        mask_ET = mask.copy()\n        mask_ET[mask_ET == 1] = 0\n        mask_ET[mask_ET == 2] = 0\n        mask_ET[mask_ET == 4] = 1\n        # exclude 2 / 1 labelled tumour \n        \n        # ED - LABEL 2\n        # mask_ED = mask.copy()\n        # mask_ED[mask_ED == 1] = 0\n        # mask_ED[mask_ED == 2] = 1\n        # mask_ED[mask_ED == 4] = 0\n\n\n        # mask = np.stack([mask_WT, mask_TC, mask_ET, mask_ED])\n        mask = np.stack([mask_WT, mask_TC, mask_ET])\n        mask = np.moveaxis(mask, (0, 1, 2, 3), (0, 3, 2, 1))\n\n        return mask        ","metadata":{"execution":{"iopub.status.busy":"2023-10-22T03:57:11.322890Z","iopub.execute_input":"2023-10-22T03:57:11.323239Z","iopub.status.idle":"2023-10-22T03:57:11.341922Z","shell.execute_reply.started":"2023-10-22T03:57:11.323214Z","shell.execute_reply":"2023-10-22T03:57:11.340840Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def get_augmentations(phase):\n    list_transforms = []\n    \n    # Does data augmentations & tranformation required for IMAGES & MASKS \n    # they include cropping, padding, flipping , rotating \n    list_trfms = Compose(list_transforms)\n    return list_trfms\n\n\ndef get_dataloader(\n    dataset: torch.utils.data.Dataset,\n    path_to_csv: str,\n    phase: str,\n    fold: int = 0,\n    batch_size: int = 1,\n    num_workers: int = 4 ):\n    \n    '''Returns: dataloader for the model training'''\n    df = pd.read_csv(path_to_csv)\n        \n    # selecting train_df to be all the entries EXCEPT the mentioned fold while calling dataloader \n    train_df = df.loc[df['fold'] != fold].reset_index(drop=True)\n    \n    # selection a particluar fold while calling the get_dataloader function \n    val_df = df.loc[df['fold'] == fold].reset_index(drop=True)\n#     test_df = df.loc[~df['Age'].notnull()].reset_index(drop=True)\n#     print(len(train_df) , len(val_df), len(test_df))\n\n    \n    # read csv --> train & validation df splitting --> assigning train_df / val_df to df based on phase --> returning dataloader \n    # how does val_df / train_df got converted to ( id , image tensor , mask tensor )\n    \n    if phase == \"train\" : \n        df = train_df \n    elif phase == \"valid\" :\n        df = val_df\n#     else:\n#         df = test_df\n    dataset = dataset(df, phase)\n    \"\"\"\n    DataLoader iteratively goes through every id in the df & gets all the individual tuples for individual ids & appends all of them \n    like this : \n    { id : ['BraTS20_Training_235'] ,\n      image : [] , \n      tensor : [] , \n    } \n    { id : ['BraTS20_Training_236'] ,\n      image : [] , \n      tensor : [] , \n    } \n    { id : ['BraTS20_Training_237'] ,\n      image : [] , \n      tensor : [] , \n    } \n    \"\"\"\n    dataloader = DataLoader(\n        dataset,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        pin_memory=True,\n        shuffle=True,   \n    )\n    return dataloader","metadata":{"execution":{"iopub.status.busy":"2023-10-22T03:57:12.139436Z","iopub.execute_input":"2023-10-22T03:57:12.140146Z","iopub.status.idle":"2023-10-22T03:57:12.149230Z","shell.execute_reply.started":"2023-10-22T03:57:12.140115Z","shell.execute_reply":"2023-10-22T03:57:12.148178Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"dataloader = get_dataloader(dataset=BratsDataset, path_to_csv='train_data.csv', phase='valid', fold=0)\nlen(dataloader)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-22T03:57:12.925082Z","iopub.execute_input":"2023-10-22T03:57:12.925943Z","iopub.status.idle":"2023-10-22T03:57:12.938387Z","shell.execute_reply.started":"2023-10-22T03:57:12.925907Z","shell.execute_reply":"2023-10-22T03:57:12.937459Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"34"},"metadata":{}}]},{"cell_type":"markdown","source":"# Metrics and Loss metrics","metadata":{}},{"cell_type":"code","source":"def dice_coef_metric(probabilities: torch.Tensor,\n                     truth: torch.Tensor, \n                     treshold: float = 0.5,\n                     eps: float = 1e-9) -> np.ndarray:\n    \"\"\"\n    Calculate Dice score for data batch.\n    Params:\n        probobilities: model outputs after activation function.\n        truth: truth values.\n        threshold: threshold for probabilities.\n        eps: additive to refine the estimate.\n        Returns: dice score aka f1.\n    \"\"\"\n    scores = []\n    num = probabilities.shape[0] \n    predictions = (probabilities >= treshold).float()\n    assert(predictions.shape == truth.shape)\n    for i in range(num):\n        prediction = predictions[i]\n        truth_ = truth[i]\n        intersection = 2.0 * (truth_ * prediction).sum()\n        union = truth_.sum() + prediction.sum()\n        if truth_.sum() == 0 and prediction.sum() == 0:\n            scores.append(1.0)\n        else:\n            scores.append((intersection + eps) / union)\n    return np.mean(scores)\n\n\ndef jaccard_coef_metric(probabilities: torch.Tensor,\n               truth: torch.Tensor,\n               treshold: float = 0.5,\n               eps: float = 1e-9) -> np.ndarray:\n    \"\"\"\n    Calculate Jaccard index for data batch.\n    Params:\n        probobilities: model outputs after activation function.\n        truth: truth values.\n        threshold: threshold for probabilities.\n        eps: additive to refine the estimate.\n        Returns: jaccard score aka iou.\"\n    \"\"\"\n    scores = []\n    num = probabilities.shape[0]\n    predictions = (probabilities >= treshold).float()\n    assert(predictions.shape == truth.shape)\n\n    for i in range(num):\n        prediction = predictions[i]\n        truth_ = truth[i]\n        intersection = (prediction * truth_).sum()\n        union = (prediction.sum() + truth_.sum()) - intersection + eps\n        if truth_.sum() == 0 and prediction.sum() == 0:\n            scores.append(1.0)\n        else:\n            scores.append((intersection + eps) / union)\n    return np.mean(scores)\n\n\nclass Meter:\n    '''factory for storing and updating iou and dice scores.'''\n    def __init__(self, treshold: float = 0.5):\n        self.threshold: float = treshold\n        self.dice_scores: list = []\n        self.iou_scores: list = []\n    \n    def update(self, logits: torch.Tensor, targets: torch.Tensor):\n        \"\"\"\n        Takes: logits from output model and targets,\n        calculates dice and iou scores, and stores them in lists.\n        calculates using the above declare functions \n        \"\"\"\n        probs = torch.sigmoid(logits)\n        dice = dice_coef_metric(probs, targets, self.threshold)\n        iou = jaccard_coef_metric(probs, targets, self.threshold)\n        \n        # appending to the respective lists \n        self.dice_scores.append(dice)\n        self.iou_scores.append(iou)\n    \n    def get_metrics(self) -> np.ndarray:\n        \"\"\"\n        Returns: the average of the accumulated dice and iou scores.\n        \"\"\"\n        dice = np.mean(self.dice_scores)\n        iou = np.mean(self.iou_scores)\n        return dice, iou\n\n\nclass DiceLoss(nn.Module):\n    \"\"\"Calculate dice loss.\"\"\"\n    def __init__(self, eps: float = 1e-9):\n        super(DiceLoss, self).__init__()\n        self.eps = eps\n        \n    def forward(self,\n                logits: torch.Tensor,\n                targets: torch.Tensor) -> torch.Tensor:\n        \n        num = targets.size(0)\n        probability = torch.sigmoid(logits)\n        probability = probability.view(num, -1)\n        targets = targets.view(num, -1)\n        assert(probability.shape == targets.shape)\n        \n        intersection = 2.0 * (probability * targets).sum()\n        union = probability.sum() + targets.sum()\n        dice_score = (intersection + self.eps) / union\n        #print(\"intersection\", intersection, union, dice_score)\n        return 1.0 - dice_score\n        \n        \nclass BCEDiceLoss(nn.Module):\n    \"\"\"Compute objective loss: BCE loss + DICE loss.\"\"\"\n    def __init__(self):\n        super(BCEDiceLoss, self).__init__()\n        self.bce = nn.BCEWithLogitsLoss()\n        self.dice = DiceLoss()\n        \n    def forward(self, \n                logits: torch.Tensor,\n                targets: torch.Tensor) -> torch.Tensor:\n        \n        # logits are the images \n        # target are the masks \n        assert(logits.shape == targets.shape)\n        dice_loss = self.dice(logits, targets)\n        bce_loss = self.bce(logits, targets)\n        \n        # binary cross entropy loss & dice loss \n        return bce_loss + dice_loss\n    \n# helper functions for testing.  \ndef dice_coef_metric_per_classes(probabilities: np.ndarray,\n                                    truth: np.ndarray,\n                                    treshold: float = 0.5,\n                                    eps: float = 1e-9,\n                                    classes: list = ['WT', 'TC', 'ET']) -> np.ndarray:\n    \"\"\"\n    Calculate Dice score for data batch and for each class i.e. 'WT', 'TC', 'ET'\n    Params:\n        probobilities: model outputs after activation function.\n        truth: model targets.\n        threshold: threshold for probabilities.\n        eps: additive to refine the estimate.\n        classes: list with name classes.\n        Returns: dict with dice scores for each class.\n    \"\"\"\n    scores = {key: list() for key in classes}\n    num = probabilities.shape[0]\n    num_classes = probabilities.shape[1]\n    predictions = (probabilities >= treshold).astype(np.float32)\n    assert(predictions.shape == truth.shape)\n\n    for i in range(num):\n        for class_ in range(num_classes):\n            prediction = predictions[i][class_]\n            truth_ = truth[i][class_]\n            intersection = 2.0 * (truth_ * prediction).sum()\n            union = truth_.sum() + prediction.sum()\n            if truth_.sum() == 0 and prediction.sum() == 0:\n                 scores[classes[class_]].append(1.0)\n            else:\n                scores[classes[class_]].append((intersection + eps) / union)\n                \n    return scores\n\n\ndef jaccard_coef_metric_per_classes(probabilities: np.ndarray, # output of the model in an array format \n               truth: np.ndarray,# masks  \n               treshold: float = 0.5, # threshold to whether segment / not \n               eps: float = 1e-9, # smooth \n               classes: list = ['WT', 'TC', 'ET']) -> np.ndarray:\n    \"\"\"\n    Calculate Jaccard index for data batch and for each class.\n    Params:\n        probobilities: model outputs after activation function.\n        truth: model targets.\n        threshold: threshold for probabilities.\n        eps: additive to refine the estimate.\n        classes: list with name classes.\n        Returns: dict with jaccard scores for each class.\"\n    \"\"\"\n    scores = {key: list() for key in classes}\n    # storing all the jaccard coefficients in a list \n    \n    num = probabilities.shape[0]\n    \n    num_classes = probabilities.shape[1]\n    \n    # segmenting if prob > threshold .i.e. setting to float32 \n    predictions = (probabilities >= treshold).astype(np.float32)\n    \n    assert(predictions.shape == truth.shape)\n\n    for i in range(num):\n        for class_ in range(num_classes):\n            prediction = predictions[i][class_]\n            truth_ = truth[i][class_]\n            intersection = (prediction * truth_).sum()\n            union = (prediction.sum() + truth_.sum()) - intersection + eps\n            if truth_.sum() == 0 and prediction.sum() == 0:\n                 scores[classes[class_]].append(1.0)\n            else:\n                scores[classes[class_]].append((intersection + eps) / union)\n\n    return scores","metadata":{"execution":{"iopub.status.busy":"2023-10-22T03:57:25.637379Z","iopub.execute_input":"2023-10-22T03:57:25.637773Z","iopub.status.idle":"2023-10-22T03:57:25.674841Z","shell.execute_reply.started":"2023-10-22T03:57:25.637736Z","shell.execute_reply":"2023-10-22T03:57:25.673935Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# 3DUnet","metadata":{}},{"cell_type":"code","source":"class DoubleConv(nn.Module):\n    \"\"\"(Conv3D -> BN -> ReLU) * 2\"\"\"\n    def __init__(self, in_channels, out_channels, num_groups=8):\n        super().__init__()\n        self.double_conv = nn.Sequential(\n            # Convlution set one \n            nn.Conv3d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n            #nn.BatchNorm3d(out_channels),\n            nn.GroupNorm(num_groups=num_groups, num_channels=out_channels),\n            nn.ReLU(inplace=True),\n\n            # Convlution set two \n            nn.Conv3d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n            #nn.BatchNorm3d(out_channels),\n            nn.GroupNorm(num_groups=num_groups, num_channels=out_channels),\n            nn.ReLU(inplace=True)\n            \n          )\n\n    def forward(self,x):\n        return self.double_conv(x)\n\n    \nclass Down(nn.Module):\n\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.encoder = nn.Sequential(\n            nn.MaxPool3d(2, 2),\n            DoubleConv(in_channels, out_channels)\n        )\n    def forward(self, x):\n        # max pooling 3d + doubleConv \n        return self.encoder(x)\n\n    \nclass Up(nn.Module):\n\n    def __init__(self, in_channels, out_channels, trilinear=True):\n        super().__init__()\n        \n        if trilinear:\n            self.up = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n        else:\n            self.up = nn.ConvTranspose3d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n            \n        self.conv = DoubleConv(in_channels, out_channels)\n\n    def forward(self, x1, x2):\n        x1 = self.up(x1)\n\n        diffZ = x2.size()[2] - x1.size()[2]\n        diffY = x2.size()[3] - x1.size()[3]\n        diffX = x2.size()[4] - x1.size()[4]\n        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2, diffZ // 2, diffZ - diffZ // 2])\n\n        x = torch.cat([x2, x1], dim=1)\n        return self.conv(x)\n\n    \nclass Out(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size = 1)\n\n    def forward(self, x):\n        return self.conv(x)\n\n\nclass UNet3d(nn.Module):\n    def __init__(self, in_channels, n_classes, n_channels):\n        super().__init__()\n        self.in_channels = in_channels\n        self.n_classes = n_classes\n        self.n_channels = n_channels\n\n        # extracting the features by incrementally multiplying the no.of channels \n        self.conv = DoubleConv(in_channels, n_channels)\n        self.enc1 = Down(n_channels, 2 * n_channels)\n        self.enc2 = Down(2 * n_channels, 4 * n_channels)\n        self.enc3 = Down(4 * n_channels, 8 * n_channels)\n        self.enc4 = Down(8 * n_channels, 8 * n_channels)\n\n        self.dec1 = Up(16 * n_channels, 4 * n_channels)\n        self.dec2 = Up(8 * n_channels, 2 * n_channels)\n        self.dec3 = Up(4 * n_channels, n_channels)\n        self.dec4 = Up(2 * n_channels, n_channels)\n        self.out = Out(n_channels, n_classes)\n\n    def forward(self, x):\n        x1 = self.conv(x)\n        x2 = self.enc1(x1)\n        x3 = self.enc2(x2)\n        x4 = self.enc3(x3)\n        x5 = self.enc4(x4)\n\n        mask = self.dec1(x5, x4)\n        mask = self.dec2(mask, x3)\n        mask = self.dec3(mask, x2)\n        mask = self.dec4(mask, x1)\n        mask = self.out(mask)\n        \n        \"\"\"\n        After a series of either Upsampling / 3d Transpose\n        a segmented image of the input image is generated \n        & returned \n        \"\"\"\n        return mask","metadata":{"execution":{"iopub.status.busy":"2023-10-22T03:57:25.676358Z","iopub.execute_input":"2023-10-22T03:57:25.676680Z","iopub.status.idle":"2023-10-22T03:57:25.697125Z","shell.execute_reply.started":"2023-10-22T03:57:25.676651Z","shell.execute_reply":"2023-10-22T03:57:25.696342Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# Trainer","metadata":{}},{"cell_type":"code","source":"class Trainer:\n\n    def __init__(self,\n                 net: nn.Module,\n                 dataset: torch.utils.data.Dataset,\n                 criterion: nn.Module,\n                 lr: float,\n                 accumulation_steps: int,\n                 batch_size: int,\n                 fold: int,\n                 num_epochs: int,\n                 path_to_csv: str,\n                 display_plot: bool = True,\n                ):\n\n        \"\"\"Initialization.\"\"\"\n        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n        print(\"device:\", self.device)\n        self.display_plot = display_plot\n        self.net = net\n        self.net = self.net.to(self.device)\n        self.criterion = criterion\n        self.optimizer = Adam(self.net.parameters(), lr=lr)\n        self.scheduler = ReduceLROnPlateau(self.optimizer, mode=\"min\",\n                                           patience=2, verbose=True)\n        self.accumulation_steps = accumulation_steps // batch_size\n        self.phases = [\"train\", \"val\"]\n        self.num_epochs = num_epochs\n\n        self.dataloaders = {\n            phase: get_dataloader(\n                dataset = dataset,\n                path_to_csv = path_to_csv,\n                phase = phase,\n                fold = fold,\n                batch_size = batch_size,\n                num_workers = 4\n            )\n            for phase in self.phases\n        }\n        self.best_loss = float(\"inf\")\n        \n        # calculating the list of losses for both train & validation phases \n        self.losses = {phase: [] for phase in self.phases}\n        \n        # calculating the dice scores for both train & validation phases \n        self.dice_scores = {phase: [] for phase in self.phases}\n        \n        # calculating the jaccard scores for both train & validation phases\n        self.jaccard_scores = {phase: [] for phase in self.phases}\n         \n    def _compute_loss_and_outputs(self,\n                                  images: torch.Tensor,\n                                  targets: torch.Tensor):\n        images = images.to(self.device)\n        targets = targets.to(self.device)\n        \n        # making images predictions symmetric using logits  \n        logits = self.net(images)\n        \n        # calculating the loss bce loss / dice loss / jaccard loss / combined loss \n        # as defined calcluating the mean square error loss \n        loss = self.criterion(logits, targets)\n        return loss, logits\n        \n    def _do_epoch(self, epoch: int, phase: str):\n        print(f\"{phase} epoch: {epoch} | time: {time.strftime('%H:%M:%S')}\")\n\n        self.net.train() if phase == \"train\" else self.net.eval()\n        meter = Meter()\n        dataloader = self.dataloaders[phase]\n        total_batches = len(dataloader)\n        running_loss = 0.0 \n        self.optimizer.zero_grad()\n        for itr, data_batch in enumerate(dataloader):\n            images, targets = data_batch['image'], data_batch['mask']\n            # BCEDiceLoss & raw prediction( logits ) are calculated \n            loss, logits = self._compute_loss_and_outputs(images, targets)\n            loss = loss / self.accumulation_steps\n            if phase == \"train\":\n                # Backpropagating the losses generated to train the Unet \n                loss.backward()\n                \n                # if a certain no. is reached then all the gradient accuwlated will be given to the optiizer & it gets trained\n                # after giving, gradient gets reset to 0 \n                if (itr + 1) % self.accumulation_steps == 0:\n                    self.optimizer.step()\n                    self.optimizer.zero_grad()\n                    \n            running_loss += loss.item()\n            print(f\"running loss of epoch {epoch} is : \", running_loss) \n            # meter.update stores running_loss for each iteration in one epoch in a list to visualize in graph \n            meter.update(logits.detach().cpu(),\n                         targets.detach().cpu()\n                        )\n            \n        epoch_loss = (running_loss * self.accumulation_steps) / total_batches\n        epoch_dice, epoch_iou = meter.get_metrics()\n        \n        self.losses[phase].append(epoch_loss)\n        self.dice_scores[phase].append(epoch_dice)\n        self.jaccard_scores[phase].append(epoch_iou)\n\n        return epoch_loss\n        \n    def run(self):\n        for epoch in range(self.num_epochs):\n            self._do_epoch(epoch, \"train\")\n            with torch.no_grad():\n                val_loss = self._do_epoch(epoch, \"val\")\n                print(f\"BCEDiceLoss for epoch {epoch} is : \" , val_loss ) \n                self.scheduler.step(val_loss)\n            if self.display_plot:\n                self._plot_train_history()\n                \n            if val_loss < self.best_loss:\n                print(f\"\\n{'#'*20}\\nSaved new checkpoint\\n{'#'*20}\\n\")\n                self.best_loss = val_loss\n                torch.save(self.net.state_dict(), \"best_model.pth\")\n            print()\n        self._save_train_history()\n            \n    def _plot_train_history(self):\n        data = [self.losses, self.dice_scores, self.jaccard_scores]\n        colors = ['deepskyblue', \"crimson\"]\n        labels = [\n            f\"\"\"\n            train loss {self.losses['train'][-1]}\n            val loss {self.losses['val'][-1]}\n            \"\"\",\n            \n            f\"\"\"\n            train dice score {self.dice_scores['train'][-1]}\n            val dice score {self.dice_scores['val'][-1]} \n            \"\"\", \n                  \n            f\"\"\"\n            train jaccard score {self.jaccard_scores['train'][-1]}\n            val jaccard score {self.jaccard_scores['val'][-1]}\n            \"\"\",\n        ]\n        \n        clear_output(True)\n        with plt.style.context(\"seaborn-dark-palette\"):\n            fig, axes = plt.subplots(3, 1, figsize=(8, 10))\n            for i, ax in enumerate(axes):\n                ax.plot(data[i]['val'], c=colors[0], label=\"val\")\n                ax.plot(data[i]['train'], c=colors[-1], label=\"train\")\n                ax.set_title(labels[i])\n                ax.legend(loc=\"upper right\")\n                \n            plt.tight_layout()\n            plt.show()\n            \n    def load_predtrain_model(self,\n                             state_path: str):\n        self.net.load_state_dict(torch.load(state_path))\n        print(\"Predtrain model loaded\")\n        \n    def _save_train_history(self):\n        \"\"\"writing model weights and training logs to files.\"\"\"\n        torch.save(self.net.state_dict(),\n                   f\"last_epoch_model.pth\")\n\n        logs_ = [self.losses, self.dice_scores, self.jaccard_scores]\n        log_names_ = [\"_loss\", \"_dice\", \"_jaccard\"]\n        logs = [logs_[i][key] for i in list(range(len(logs_)))\n                         for key in logs_[i]]\n        log_names = [key+log_names_[i] \n                     for i in list(range(len(logs_))) \n                     for key in logs_[i]\n                    ]\n        pd.DataFrame(\n            dict(zip(log_names, logs))\n        ).to_csv(\"train_log.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-22T00:30:13.574275Z","iopub.execute_input":"2023-10-22T00:30:13.574609Z","iopub.status.idle":"2023-10-22T00:30:13.608989Z","shell.execute_reply.started":"2023-10-22T00:30:13.574582Z","shell.execute_reply":"2023-10-22T00:30:13.607700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training the UNet3D","metadata":{}},{"cell_type":"code","source":"nodel = UNet3d(in_channels=4, n_classes=3, n_channels=24).to('cuda')","metadata":{"execution":{"iopub.status.busy":"2023-10-22T00:30:13.610322Z","iopub.execute_input":"2023-10-22T00:30:13.610982Z","iopub.status.idle":"2023-10-22T00:30:13.690136Z","shell.execute_reply.started":"2023-10-22T00:30:13.610943Z","shell.execute_reply":"2023-10-22T00:30:13.689060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(net=nodel,\n                  dataset=BratsDataset,\n                  criterion=BCEDiceLoss(),\n                  lr=5e-4,\n                  accumulation_steps=4,\n                  batch_size=1,\n                  fold=0,\n                  num_epochs=1,\n                  path_to_csv = config.path_to_csv,)\n\nif config.pretrained_model_path is not None:\n    trainer.load_predtrain_model(config.pretrained_model_path)\n    \n    # if need - load the logs.      \n    train_logs = pd.read_csv(config.train_logs_path)\n    trainer.losses[\"train\"] =  train_logs.loc[:, \"train_loss\"].to_list()\n    trainer.losses[\"val\"] =  train_logs.loc[:, \"val_loss\"].to_list()\n    trainer.dice_scores[\"train\"] = train_logs.loc[:, \"train_dice\"].to_list()\n    trainer.dice_scores[\"val\"] = train_logs.loc[:, \"val_dice\"].to_list()\n    trainer.jaccard_scores[\"train\"] = train_logs.loc[:, \"train_jaccard\"].to_list()\n    trainer.jaccard_scores[\"val\"] = train_logs.loc[:, \"val_jaccard\"].to_list()","metadata":{"execution":{"iopub.status.busy":"2023-10-22T00:30:13.691298Z","iopub.execute_input":"2023-10-22T00:30:13.691620Z","iopub.status.idle":"2023-10-22T00:30:14.248698Z","shell.execute_reply.started":"2023-10-22T00:30:13.691592Z","shell.execute_reply":"2023-10-22T00:30:14.247585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training time(t0) starts \nt0 = time.time() ","metadata":{"execution":{"iopub.status.busy":"2023-10-22T00:30:14.250006Z","iopub.execute_input":"2023-10-22T00:30:14.250435Z","iopub.status.idle":"2023-10-22T00:30:14.255374Z","shell.execute_reply.started":"2023-10-22T00:30:14.250380Z","shell.execute_reply":"2023-10-22T00:30:14.254365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.run()","metadata":{"execution":{"iopub.status.busy":"2023-10-22T00:30:14.256779Z","iopub.execute_input":"2023-10-22T00:30:14.257148Z","iopub.status.idle":"2023-10-22T00:47:05.338262Z","shell.execute_reply.started":"2023-10-22T00:30:14.257112Z","shell.execute_reply":"2023-10-22T00:47:05.336921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# total training time(tt) \nt1 = time.time()\ntt = t1 - t0 \nprint(\"Training time : \",tt)","metadata":{"execution":{"iopub.status.busy":"2023-10-22T00:47:05.339956Z","iopub.execute_input":"2023-10-22T00:47:05.340331Z","iopub.status.idle":"2023-10-22T00:47:05.349062Z","shell.execute_reply.started":"2023-10-22T00:47:05.340293Z","shell.execute_reply":"2023-10-22T00:47:05.347875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model serialization","metadata":{}},{"cell_type":"markdown","source":"#### A state dictionary contains only the learnable parameters.Whereas the entire model object includes the model architecture, optimizer state, and potentially other attributes. By saving only the state dictionary, you can significantly reduce the file size of the saved model.\n\n#### Therefore i'm serializing the state dictionary of the UNET3D model","metadata":{}},{"cell_type":"code","source":"torch.save(nodel.state_dict(), 'unet3d_state_dict.pth')\ntorch.save(nodel, 'unet3d_model.pth')","metadata":{"execution":{"iopub.status.busy":"2023-10-22T00:47:05.351054Z","iopub.execute_input":"2023-10-22T00:47:05.351511Z","iopub.status.idle":"2023-10-22T00:47:05.457861Z","shell.execute_reply.started":"2023-10-22T00:47:05.351469Z","shell.execute_reply":"2023-10-22T00:47:05.456932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-10-22T00:47:05.459021Z","iopub.execute_input":"2023-10-22T00:47:05.459341Z","iopub.status.idle":"2023-10-22T00:47:05.744767Z","shell.execute_reply.started":"2023-10-22T00:47:05.459313Z","shell.execute_reply":"2023-10-22T00:47:05.743654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Trainer performance evaluation","metadata":{}},{"cell_type":"code","source":"# Loading the serialized model to avoid computation\nnodel = torch.load('/kaggle/input/brats-ser-models-and-dataframes/unet3d_model.pth')\n\n# Turning on Evaluation mode of the model\nnodel.eval()","metadata":{"execution":{"iopub.status.busy":"2023-10-22T03:57:45.526743Z","iopub.execute_input":"2023-10-22T03:57:45.527103Z","iopub.status.idle":"2023-10-22T03:57:45.885804Z","shell.execute_reply.started":"2023-10-22T03:57:45.527073Z","shell.execute_reply":"2023-10-22T03:57:45.884836Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"UNet3d(\n  (conv): DoubleConv(\n    (double_conv): Sequential(\n      (0): Conv3d(4, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n      (1): GroupNorm(8, 24, eps=1e-05, affine=True)\n      (2): ReLU(inplace=True)\n      (3): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n      (4): GroupNorm(8, 24, eps=1e-05, affine=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (enc1): Down(\n    (encoder): Sequential(\n      (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (1): DoubleConv(\n        (double_conv): Sequential(\n          (0): Conv3d(24, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n          (1): GroupNorm(8, 48, eps=1e-05, affine=True)\n          (2): ReLU(inplace=True)\n          (3): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n          (4): GroupNorm(8, 48, eps=1e-05, affine=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (enc2): Down(\n    (encoder): Sequential(\n      (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (1): DoubleConv(\n        (double_conv): Sequential(\n          (0): Conv3d(48, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n          (1): GroupNorm(8, 96, eps=1e-05, affine=True)\n          (2): ReLU(inplace=True)\n          (3): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n          (4): GroupNorm(8, 96, eps=1e-05, affine=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (enc3): Down(\n    (encoder): Sequential(\n      (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (1): DoubleConv(\n        (double_conv): Sequential(\n          (0): Conv3d(96, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n          (1): GroupNorm(8, 192, eps=1e-05, affine=True)\n          (2): ReLU(inplace=True)\n          (3): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n          (4): GroupNorm(8, 192, eps=1e-05, affine=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (enc4): Down(\n    (encoder): Sequential(\n      (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (1): DoubleConv(\n        (double_conv): Sequential(\n          (0): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n          (1): GroupNorm(8, 192, eps=1e-05, affine=True)\n          (2): ReLU(inplace=True)\n          (3): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n          (4): GroupNorm(8, 192, eps=1e-05, affine=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (dec1): Up(\n    (up): Upsample(scale_factor=2.0, mode='trilinear')\n    (conv): DoubleConv(\n      (double_conv): Sequential(\n        (0): Conv3d(384, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n        (1): GroupNorm(8, 96, eps=1e-05, affine=True)\n        (2): ReLU(inplace=True)\n        (3): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n        (4): GroupNorm(8, 96, eps=1e-05, affine=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (dec2): Up(\n    (up): Upsample(scale_factor=2.0, mode='trilinear')\n    (conv): DoubleConv(\n      (double_conv): Sequential(\n        (0): Conv3d(192, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n        (1): GroupNorm(8, 48, eps=1e-05, affine=True)\n        (2): ReLU(inplace=True)\n        (3): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n        (4): GroupNorm(8, 48, eps=1e-05, affine=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (dec3): Up(\n    (up): Upsample(scale_factor=2.0, mode='trilinear')\n    (conv): DoubleConv(\n      (double_conv): Sequential(\n        (0): Conv3d(96, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n        (1): GroupNorm(8, 24, eps=1e-05, affine=True)\n        (2): ReLU(inplace=True)\n        (3): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n        (4): GroupNorm(8, 24, eps=1e-05, affine=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (dec4): Up(\n    (up): Upsample(scale_factor=2.0, mode='trilinear')\n    (conv): DoubleConv(\n      (double_conv): Sequential(\n        (0): Conv3d(48, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n        (1): GroupNorm(8, 24, eps=1e-05, affine=True)\n        (2): ReLU(inplace=True)\n        (3): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n        (4): GroupNorm(8, 24, eps=1e-05, affine=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (out): Out(\n    (conv): Conv3d(24, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"test_dataloader = get_dataloader(dataset=BratsDataset, path_to_csv='train_data.csv', phase=\"valid\", fold=1)\nlen(test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-10-22T03:57:51.854848Z","iopub.execute_input":"2023-10-22T03:57:51.855214Z","iopub.status.idle":"2023-10-22T03:57:51.868238Z","shell.execute_reply.started":"2023-10-22T03:57:51.855184Z","shell.execute_reply":"2023-10-22T03:57:51.867317Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"34"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix, classification_report\n\ngc.collect() \ndef compute_metrics(model, dataloader, threshold=0.33):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model.eval()\n\n    true_positives = 0\n    false_positives = 0\n    true_negatives = 0\n    false_negatives = 0\n\n    counter = 0  # Counter to keep track of the number of entries processed\n    m_logits = []\n    m_targets = []\n    with torch.no_grad():\n        for data in dataloader:\n            \n            images, targets = data['image'], data['mask']\n            images = images.to(device)\n            targets = targets.to(device)\n\n            logits = model(images)\n            \n            \n            probabilities = torch.sigmoid(logits)\n            \n            \n            predictions = (probabilities >= threshold).float()\n            \n            \n            m_logits.append(np.array(logits.cpu()))\n            m_targets.append(np.array(targets.cpu()))\n            # Compute binary segmentation metrics\n            true_positives += torch.sum((predictions == 1) & (targets == 1)).item()\n            false_positives += torch.sum((predictions == 1) & (targets == 0)).item()\n            true_negatives += torch.sum((predictions == 0) & (targets == 0)).item()\n            false_negatives += torch.sum((predictions == 0) & (targets == 1)).item()\n\n            counter += 1\n\n            # Free memory by clearing intermediate variables\n            del images, targets, logits, probabilities, predictions\n            torch.cuda.empty_cache()\n    m_logits = np.stack(m_logits,axis = 0)\n    m_targets = np.stack(m_targets,axis=0)\n    with open('logits.npy','wb') as f:\n        np.save(f,m_logits)\n    with open('targets.npy','wb') as f:\n        np.save(f,m_targets)\n    \n    return true_positives , false_positives , true_negatives , false_negatives\n\ntp , fp , tn , fn  = compute_metrics(nodel, test_dataloader, threshold=0.33)","metadata":{"execution":{"iopub.status.busy":"2023-10-22T03:59:48.218874Z","iopub.execute_input":"2023-10-22T03:59:48.219811Z","iopub.status.idle":"2023-10-22T04:01:05.022725Z","shell.execute_reply.started":"2023-10-22T03:59:48.219775Z","shell.execute_reply":"2023-10-22T04:01:05.021601Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"print(f\"True positives : {tp}\")\nprint(f\"False positives : {fp}\")\nprint(f\"True Negatives : {tn}\")\nprint(f\"False Negatives : {fn}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-22T00:47:36.213308Z","iopub.execute_input":"2023-10-22T00:47:36.214162Z","iopub.status.idle":"2023-10-22T00:47:36.220676Z","shell.execute_reply.started":"2023-10-22T00:47:36.214120Z","shell.execute_reply":"2023-10-22T00:47:36.219385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation metrics","metadata":{}},{"cell_type":"code","source":"accuracy = (tp + tn) / (tp + tn + fp + fn)\nprecision = tp / (tp + fp)\nrecall = tp / (tp + fn)\nf1_score = 2 * (precision * recall) / (precision + recall)","metadata":{"execution":{"iopub.status.busy":"2023-10-22T00:47:36.554405Z","iopub.execute_input":"2023-10-22T00:47:36.554853Z","iopub.status.idle":"2023-10-22T00:47:36.561075Z","shell.execute_reply.started":"2023-10-22T00:47:36.554814Z","shell.execute_reply":"2023-10-22T00:47:36.559922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Accuracy : {accuracy*100}\")\nprint(f\"Precision : {precision*100}\")\nprint(f\"Recall : {recall*100}\")\nprint(f\"F1 Score : {f1_score*100}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-22T00:47:36.562714Z","iopub.execute_input":"2023-10-22T00:47:36.563128Z","iopub.status.idle":"2023-10-22T00:47:36.574154Z","shell.execute_reply.started":"2023-10-22T00:47:36.563090Z","shell.execute_reply":"2023-10-22T00:47:36.573073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the best from 2013 and ensembling","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\nA = []\nwith open('/kaggle/input/semantic-logits/logits.npy','rb') as f:\n    A = np.load(f)[:10,:,0,:,:,:]\ntargets = []\nwith open('/kaggle/working/targets.npy','rb') as f:\n    targets = np.load(f)[:10,:,0,:152,:,:]\nB = []\nwith open('/kaggle/working/logits.npy','rb') as f:\n    B = np.load(f)[:10,:,0,:152,:,:]\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-22T04:17:09.054753Z","iopub.execute_input":"2023-10-22T04:17:09.055143Z","iopub.status.idle":"2023-10-22T04:17:11.809056Z","shell.execute_reply.started":"2023-10-22T04:17:09.055112Z","shell.execute_reply":"2023-10-22T04:17:11.808245Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def sigm(x):\n    return 1/(1+np.exp(-x))\n\ndef OLS(a,b):\n    return np.sum(np.square(a-b))\n\ndef BinaryEntropy(actual,prediction):\n    return -np.sum(actual*np.log(prediction+1e-7) + (1-actual)*np.log(1-prediction+1e-7))","metadata":{"execution":{"iopub.status.busy":"2023-10-22T05:00:24.675014Z","iopub.execute_input":"2023-10-22T05:00:24.675519Z","iopub.status.idle":"2023-10-22T05:00:24.681570Z","shell.execute_reply.started":"2023-10-22T05:00:24.675489Z","shell.execute_reply":"2023-10-22T05:00:24.680560Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"alphas = np.linspace(0,1,100)\n\nfor alpha in alphas:\n    print(alpha, OLS(targets,sigm(alpha*A + (1-alpha)*B)), BinaryEntropy(targets,sigm(alpha*A + (1-alpha)*B)))","metadata":{"execution":{"iopub.status.busy":"2023-10-22T05:00:55.277988Z","iopub.execute_input":"2023-10-22T05:00:55.278769Z","iopub.status.idle":"2023-10-22T05:04:51.828681Z","shell.execute_reply.started":"2023-10-22T05:00:55.278736Z","shell.execute_reply":"2023-10-22T05:04:51.827728Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"0.0 181065.47 1178246.0\n0.010101010101010102 180877.23 1167755.8\n0.020202020202020204 180685.69 1157260.1\n0.030303030303030304 180490.33 1146724.2\n0.04040404040404041 180291.03 1136186.1\n0.05050505050505051 180088.12 1125648.6\n0.06060606060606061 179881.0 1115083.6\n0.07070707070707072 179669.67 1104520.4\n0.08080808080808081 179454.2 1093943.9\n0.09090909090909091 179234.58 1083347.9\n0.10101010101010102 179010.39 1072767.8\n0.11111111111111112 178781.67 1062179.9\n0.12121212121212122 178548.12 1051610.4\n0.13131313131313133 178309.9 1041045.2\n0.14141414141414144 178066.34 1030479.6\n0.15151515151515152 177817.9 1019943.9\n0.16161616161616163 177564.06 1009422.0\n0.17171717171717174 177304.83 998900.2\n0.18181818181818182 177039.94 988410.25\n0.19191919191919193 176769.22 977959.3\n0.20202020202020204 176492.8 967544.5\n0.21212121212121213 176210.03 957186.56\n0.22222222222222224 175921.14 946868.06\n0.23232323232323235 175625.6 936606.5\n0.24242424242424243 175323.39 926406.4\n0.25252525252525254 175014.48 916290.0\n0.26262626262626265 174698.45 906247.7\n0.27272727272727276 174375.06 896316.2\n0.2828282828282829 174044.27 886476.56\n0.29292929292929293 173705.72 876779.9\n0.30303030303030304 173359.14 867222.9\n0.31313131313131315 173004.61 857829.6\n0.32323232323232326 172641.7 848613.75\n0.33333333333333337 172270.16 839602.0\n0.3434343434343435 171889.72 830833.8\n0.3535353535353536 171500.53 822333.6\n0.36363636363636365 171101.95 814129.4\n0.37373737373737376 170694.31 806272.6\n0.38383838383838387 170276.97 798801.3\n0.393939393939394 169850.64 791772.94\n0.4040404040404041 169414.47 785239.1\n0.4141414141414142 168968.42 779276.4\n0.42424242424242425 168513.42 773956.44\n0.43434343434343436 168049.2 769368.7\n0.4444444444444445 167577.11 765617.6\n0.4545454545454546 167095.55 762813.3\n0.4646464646464647 166606.53 761081.3\n0.4747474747474748 166109.44 760581.06\n0.48484848484848486 165606.77 761476.56\n0.494949494949495 165097.03 763969.8\n0.5050505050505051 164587.22 768279.56\n0.5151515151515152 164076.33 774660.2\n0.5252525252525253 163569.14 783403.56\n0.5353535353535354 163070.72 794848.8\n0.5454545454545455 162590.19 809365.9\n0.5555555555555556 162131.89 827399.4\n0.5656565656565657 161708.72 849454.75\n0.5757575757575758 161332.45 876087.3\n0.5858585858585859 161022.9 907962.5\n0.595959595959596 160803.97 945823.94\n0.6060606060606061 160705.02 990514.56\n0.6161616161616162 160764.19 1043027.1\n0.6262626262626263 161033.81 1104464.9\n0.6363636363636365 161578.83 1176103.2\n0.6464646464646465 162483.97 1259406.0\n0.6565656565656566 163859.95 1356017.4\n0.6666666666666667 165846.31 1467849.5\n0.6767676767676768 168626.83 1597057.2\n0.686868686868687 172437.56 1746121.8\n0.696969696969697 177583.66 1917838.4\n0.7070707070707072 184456.72 2115422.2\n0.7171717171717172 193561.78 2342505.5\n0.7272727272727273 205547.25 2603232.8\n0.7373737373737375 221245.3 2902293.2\n0.7474747474747475 241719.86 3244991.5\n0.7575757575757577 268326.8 3637360.5\n0.7676767676767677 302794.25 4086170.0\n0.7777777777777778 347307.72 4599063.5\n0.787878787878788 404627.72 5184616.5\n0.797979797979798 478216.0 5852430.0\n0.8080808080808082 572392.7 6613194.5\n0.8181818181818182 692513.0 7478794.5\n0.8282828282828284 845160.0 8462390.0\n0.8383838383838385 1038354.75 9578387.0\n0.8484848484848485 1281766.2 10842631.0\n0.8585858585858587 1586915.9 12272216.0\n0.8686868686868687 1967334.6 13885512.0\n0.8787878787878789 2438649.5 15702401.0\n0.888888888888889 3018570.0 17743336.0\n0.8989898989898991 3726715.0 20030108.0\n0.9090909090909092 4584263.0 22584934.0\n0.9191919191919192 5613272.0 25430396.0\n0.9292929292929294 6835872.0 28588532.0\n0.9393939393939394 8272968.5 32081296.0\n0.9494949494949496 9942976.0 35928692.0\n0.9595959595959597 11860080.0 40149604.0\n0.9696969696969697 14032766.0 44760410.0\n0.9797979797979799 16462182.0 49774196.0\n0.98989898989899 19141170.0 55200840.0\n1.0 22053440.0 61053096.0\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}